name: evaluation_dataset_preprocessor
description: |
  Preprocesses a dataset for Evaluated Annotation and Vision Error Analysis pipelines.

  Args:
      project (str):
          Required. GCP Project ID.
      location (Optional[str]):
          GCP Region.
          If not set, defaulted to `us-central1`.
      output_dir (str):
          Required. The Google Cloud Storage location where the outputs will be saved to.
      model (Optional[google.VertexModel])
          Optional. A Vertex Model Artifact. Used to retrieve training dataset used for AutoML training.
      test_dataset (Optional[str])
          Optional. A string of test-split Vertex Dataset Resource ID. If `test_dataset_storage_source_uris` is
          also provided, this Vertex Dataset will override the GCS source.
      test_dataset_storage_source_uris (Optional[Sequence[str]]):
          Optional. Google Cloud Storage URI(-s) to unmanaged test datasets.`jsonl` is currently the
          only allowed format.
          If `test_dataset_storage_source_uris` is also provided, this field will be overriden by the
          provided Vertex Dataset.
      train_dataset_storage_source_uris (Optional[Sequence[str]]):
          Optional. Google Cloud Storage URI(-s) to unmanaged test datasets.`jsonl` is currently the
          only allowed format. Must be provided if input `model` is not specified.

          May contain wildcards. For more information on wildcards, see
          https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.
  Returns:
      batch_prediction_storage_source (str)
        Google Cloud Storage URI(-s) to preprocessed dataset instances for Vertex Batch Prediction
        component. Target field name is removed.
        For example,
          {"content":"gs://flowers/roses/001.jpg","mimeType":"image/jpeg"}
      model_evaluation_storage_source (str)
        Google Cloud Storage URI(-s) to preprocessed dataset instances for Vertex Model Evaluation
        component. Target field name is defaulted to "ground_truth".
        For example,
          {"content":"gs://flowers/roses/001.jpg","mimeType":"image/jpeg", "ground_truth": "roses"}
      test_data_items_storage_source (str)
        Google Cloud Storage URI(-s) to preprocessed testing dataset instances for Evaluated
        Annotation or Vision Error Analysis pipelines. It is the input source for Evaluated
        Annotation component and Feature Extraction component.
        For example,
          {"dataItemID":"123456",
           "imageGcsUri":"gs://flowers/roses/001.jpg",
           "annotation_resource_name":'projects/1111/locations/us-central1/datasets/2222/dataItems/3333/annotations/4444',
           "ground_truth_annotation":"roses",
           "annotationSpecID": "654321",
           "annotation_set_name":"987654321",
           "dataItemResourceLabels":{"aiplatform.googleapis.com/ml_use":"test"}}
      train_data_items_storage_source (str)
        Google Cloud Storage URI(-s) to preprocessed training dataset instances for Vision Error
        Analysis pipelines. It is the input source for Feature Extraction component. It uses the
        same output format as test_data_items_storage_source.
inputs:
  - { name: project, type: String }
  - { name: location, type: String, default: "us-central1" }
  - { name: output_dir, type: String }
  - { name: model, type: google.VertexModel, optional: True }
  - { name: test_dataset, type: String, default: "", optional: True }
  - { name: test_dataset_storage_source_uris, type: JsonArray, default: "[]", optional: True }
  - { name: train_dataset_storage_source_uris, type: JsonArray, default: "[]", optional: True }
outputs:
  - { name: gcp_resources, type: String }
  - { name: batch_prediction_storage_source, type: String }
  - { name: model_evaluation_storage_source, type: String }
  - { name: test_data_items_storage_source, type: String }
  - { name: train_data_items_storage_source, type: String }
implementation:
  container:
    image: gcr.io/ml-pipeline/model-evaluation:v0.8
    command:
      - python
      - /dataset_preprocessor.py
    args:
      - --task
      - "dataset_preprocessor"
      - --project_id
      - { inputValue: project }
      - --location
      - { inputValue: location }
      - --output_dir
      - { inputValue: output_dir}
      - if:
          cond: { isPresent: model }
          then:
            - --model
            - "{{$.inputs.artifacts['model'].metadata['resourceName']}}"
      - --test_dataset
      - { inputValue: test_dataset }
      - --test_dataset_storage_source_uris
      - { inputValue: test_dataset_storage_source_uris }
      - --train_dataset_storage_source_uris
      - { inputValue: train_dataset_storage_source_uris }
      - --batch_prediction_storage_source
      - { outputPath: batch_prediction_storage_source }
      - --model_evaluation_storage_source
      - { outputPath: model_evaluation_storage_source }
      - --test_data_items_storage_source
      - { outputPath: test_data_items_storage_source }
      - --train_data_items_storage_source
      - { outputPath: train_data_items_storage_source }
      - --gcp_resources
      - { outputPath: gcp_resources }
      - --executor_input
      - "{{$}}"
